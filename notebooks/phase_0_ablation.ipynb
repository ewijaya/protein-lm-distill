{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Phase 0: Methodological Enhancements - Ablation Study\n",
    "\n",
    "This notebook validates the Phase 0 protein-specific distillation enhancements:\n",
    "\n",
    "1. **Uncertainty-Aware Position Weighting**: Weights distillation loss by position-specific entropy from teacher predictions\n",
    "2. **Calibration-Aware Distillation**: Applies dynamic label smoothing based on teacher confidence\n",
    "\n",
    "We compare four configurations:\n",
    "- Baseline (no enhancements)\n",
    "- +Uncertainty weighting only\n",
    "- +Calibration smoothing only\n",
    "- +Both enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "from src.distillation import DistillationTrainer\n",
    "import config\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 2. Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher model\n",
    "print(\"Loading teacher model...\")\n",
    "teacher_model = GPT2LMHeadModel.from_pretrained(config.TEACHER_MODEL).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(config.TEACHER_MODEL)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "teacher_model.eval()\n",
    "print(f\"Teacher parameters: {sum(p.numel() for p in teacher_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "## 3. Test Enhancement Methods\n",
    "\n",
    "Before training, let's verify the enhancement methods work correctly on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-entropy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test entropy computation\n",
    "test_sequence = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
    "inputs = tokenizer(test_sequence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = teacher_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Compute entropy using the method from DistillationTrainer\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "log_probs = torch.log(probs + 1e-10)\n",
    "entropy = -torch.sum(probs * log_probs, dim=-1)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Entropy shape: {entropy.shape}\")\n",
    "print(f\"Entropy range: [{entropy.min().item():.3f}, {entropy.max().item():.3f}]\")\n",
    "print(f\"Entropy mean: {entropy.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test position weighting\n",
    "entropy_squeezed = entropy.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "# Normalize entropy to [0, 1]\n",
    "entropy_min = entropy_squeezed.min()\n",
    "entropy_max = entropy_squeezed.max()\n",
    "normalized = (entropy_squeezed - entropy_min) / (entropy_max - entropy_min + 1e-8)\n",
    "\n",
    "# Scale to [0.5, 1.0]\n",
    "weights = 0.5 + 0.5 * normalized\n",
    "\n",
    "print(f\"Weights shape: {weights.shape}\")\n",
    "print(f\"Weights range: [{weights.min().item():.3f}, {weights.max().item():.3f}]\")\n",
    "print(f\"Weights mean: {weights.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-smoothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calibration smoothing\n",
    "smoothing_factor = 0.1\n",
    "\n",
    "# Get max probability (confidence) at each position\n",
    "max_prob = probs.max(dim=-1, keepdim=True)[0]\n",
    "\n",
    "# Adaptive smoothing: more smoothing when less confident\n",
    "adaptive_smoothing = smoothing_factor * (1.0 - max_prob)\n",
    "\n",
    "# Apply smoothing\n",
    "vocab_size = probs.size(-1)\n",
    "uniform = torch.ones_like(probs) / vocab_size\n",
    "smoothed_probs = (1.0 - adaptive_smoothing) * probs + adaptive_smoothing * uniform\n",
    "\n",
    "# Verify still valid probability distribution\n",
    "print(f\"Original probs sum (should be 1): {probs.sum(dim=-1).mean().item():.6f}\")\n",
    "print(f\"Smoothed probs sum (should be 1): {smoothed_probs.sum(dim=-1).mean().item():.6f}\")\n",
    "print(f\"Max adaptive smoothing: {adaptive_smoothing.max().item():.4f}\")\n",
    "print(f\"Min adaptive smoothing: {adaptive_smoothing.min().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vis-header",
   "metadata": {},
   "source": [
    "## 4. Visualize Position-wise Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vis-entropy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize entropy and weights along the sequence\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "positions = range(len(entropy_squeezed.cpu().numpy()))\n",
    "entropy_np = entropy_squeezed.cpu().numpy()\n",
    "weights_np = weights.cpu().numpy()\n",
    "max_prob_np = max_prob.squeeze().cpu().numpy()\n",
    "\n",
    "# Entropy\n",
    "axes[0].bar(positions, entropy_np, alpha=0.7, color='steelblue')\n",
    "axes[0].set_ylabel('Entropy')\n",
    "axes[0].set_title('Teacher Prediction Entropy per Position')\n",
    "axes[0].axhline(y=entropy_np.mean(), color='red', linestyle='--', label=f'Mean: {entropy_np.mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Position weights\n",
    "axes[1].bar(positions, weights_np, alpha=0.7, color='orange')\n",
    "axes[1].set_ylabel('Weight')\n",
    "axes[1].set_title('Position Weights for Uncertainty-Aware Distillation')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', label='Min weight (0.5)')\n",
    "axes[1].axhline(y=1.0, color='gray', linestyle=':', label='Max weight (1.0)')\n",
    "axes[1].legend()\n",
    "\n",
    "# Max probability (confidence)\n",
    "axes[2].bar(positions, max_prob_np, alpha=0.7, color='green')\n",
    "axes[2].set_ylabel('Max Probability')\n",
    "axes[2].set_xlabel('Sequence Position')\n",
    "axes[2].set_title('Teacher Confidence (Max Probability) per Position')\n",
    "axes[2].axhline(y=max_prob_np.mean(), color='red', linestyle='--', label=f'Mean: {max_prob_np.mean():.2f}')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece-header",
   "metadata": {},
   "source": [
    "## 5. Test ECE Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scripts to path and import ECE function\n",
    "sys.path.insert(0, str(project_root / 'scripts'))\n",
    "from evaluate import compute_ece, get_test_sequences\n",
    "\n",
    "# Get test sequences\n",
    "test_sequences = get_test_sequences(num_sequences=10)\n",
    "print(f\"Number of test sequences: {len(test_sequences)}\")\n",
    "\n",
    "# Compute ECE for teacher\n",
    "teacher_ece = compute_ece(teacher_model, tokenizer, test_sequences[:5], device, n_bins=10)\n",
    "print(f\"\\nTeacher ECE: {teacher_ece['ece']:.4f}\")\n",
    "print(f\"Teacher MCE (max calibration error): {teacher_ece['mce']:.4f}\")\n",
    "print(f\"Overall accuracy: {teacher_ece['overall_accuracy']:.4f}\")\n",
    "print(f\"Overall confidence: {teacher_ece['overall_confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vis-reliability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reliability diagram\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Extract bin statistics\n",
    "bin_stats = teacher_ece['bin_stats']\n",
    "confidences = []\n",
    "accuracies = []\n",
    "counts = []\n",
    "\n",
    "for stat in bin_stats:\n",
    "    if stat['count'] > 0:\n",
    "        confidences.append(stat['avg_confidence'])\n",
    "        accuracies.append(stat['avg_accuracy'])\n",
    "        counts.append(stat['count'])\n",
    "\n",
    "# Scatter plot with size proportional to count\n",
    "sizes = [c / max(counts) * 500 + 50 for c in counts]\n",
    "ax.scatter(confidences, accuracies, s=sizes, alpha=0.7, label='Bins')\n",
    "\n",
    "# Perfect calibration line\n",
    "ax.plot([0, 1], [0, 1], 'r--', label='Perfect calibration')\n",
    "\n",
    "ax.set_xlabel('Mean Confidence')\n",
    "ax.set_ylabel('Mean Accuracy')\n",
    "ax.set_title(f'Teacher Model Reliability Diagram (ECE={teacher_ece[\"ece\"]:.4f})')\n",
    "ax.legend()\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_aspect('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ablation-header",
   "metadata": {},
   "source": [
    "## 6. Run Ablation Experiments\n",
    "\n",
    "This section provides commands to run the ablation study. Due to training time, we provide the commands to run separately.\n",
    "\n",
    "### Training Commands\n",
    "\n",
    "```bash\n",
    "# Baseline (no enhancements)\n",
    "python scripts/train.py \\\n",
    "    --temperature 2.0 --alpha 0.5 \\\n",
    "    --n_layer 4 --n_head 4 --n_embd 512 \\\n",
    "    --train_size_prop 0.05 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --output_dir ./models/ablation-baseline\n",
    "\n",
    "# +Uncertainty weighting only\n",
    "python scripts/train.py \\\n",
    "    --temperature 2.0 --alpha 0.5 \\\n",
    "    --n_layer 4 --n_head 4 --n_embd 512 \\\n",
    "    --train_size_prop 0.05 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --use_uncertainty_weighting \\\n",
    "    --output_dir ./models/ablation-uncertainty\n",
    "\n",
    "# +Calibration smoothing only\n",
    "python scripts/train.py \\\n",
    "    --temperature 2.0 --alpha 0.5 \\\n",
    "    --n_layer 4 --n_head 4 --n_embd 512 \\\n",
    "    --train_size_prop 0.05 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --use_calibration_smoothing \\\n",
    "    --smoothing_factor 0.1 \\\n",
    "    --output_dir ./models/ablation-calibration\n",
    "\n",
    "# +Both enhancements\n",
    "python scripts/train.py \\\n",
    "    --temperature 2.0 --alpha 0.5 \\\n",
    "    --n_layer 4 --n_head 4 --n_embd 512 \\\n",
    "    --train_size_prop 0.05 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --use_uncertainty_weighting \\\n",
    "    --use_calibration_smoothing \\\n",
    "    --smoothing_factor 0.1 \\\n",
    "    --output_dir ./models/ablation-both\n",
    "```\n",
    "\n",
    "### Evaluation Commands\n",
    "\n",
    "```bash\n",
    "for model in baseline uncertainty calibration both; do\n",
    "    python scripts/evaluate.py \\\n",
    "        --student_model ./models/ablation-${model} \\\n",
    "        --num_samples 100 \\\n",
    "        --compute_ece \\\n",
    "        --output results/ablation_${model}.json\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## 7. Load and Compare Ablation Results\n",
    "\n",
    "After running the experiments, load and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ablation results (if available)\n",
    "results_dir = project_root / 'results'\n",
    "ablation_files = {\n",
    "    'Baseline': results_dir / 'ablation_baseline.json',\n",
    "    '+Uncertainty': results_dir / 'ablation_uncertainty.json',\n",
    "    '+Calibration': results_dir / 'ablation_calibration.json',\n",
    "    '+Both': results_dir / 'ablation_both.json',\n",
    "}\n",
    "\n",
    "ablation_results = {}\n",
    "for name, path in ablation_files.items():\n",
    "    if path.exists():\n",
    "        with open(path) as f:\n",
    "            ablation_results[name] = json.load(f)\n",
    "        print(f\"Loaded {name}\")\n",
    "    else:\n",
    "        print(f\"Not found: {path}\")\n",
    "\n",
    "if ablation_results:\n",
    "    print(f\"\\nLoaded {len(ablation_results)} ablation results\")\n",
    "else:\n",
    "    print(\"\\nNo ablation results found. Run the training commands above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results if available\n",
    "if ablation_results:\n",
    "    print(\"Ablation Study Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Configuration':<20} {'PPL Ratio':>12} {'KL Div':>12} {'ECE':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, result in ablation_results.items():\n",
    "        ppl_ratio = result.get('perplexity_ratio', 'N/A')\n",
    "        kl_div = result.get('kl_divergence', 'N/A')\n",
    "        ece = result.get('student_ece', {}).get('ece', 'N/A') if 'student_ece' in result else 'N/A'\n",
    "        \n",
    "        if isinstance(ppl_ratio, (int, float)):\n",
    "            ppl_str = f\"{ppl_ratio:.4f}\"\n",
    "        else:\n",
    "            ppl_str = str(ppl_ratio)\n",
    "            \n",
    "        if isinstance(kl_div, (int, float)):\n",
    "            kl_str = f\"{kl_div:.4f}\"\n",
    "        else:\n",
    "            kl_str = str(kl_div)\n",
    "            \n",
    "        if isinstance(ece, (int, float)):\n",
    "            ece_str = f\"{ece:.4f}\"\n",
    "        else:\n",
    "            ece_str = str(ece)\n",
    "        \n",
    "        print(f\"{name:<20} {ppl_str:>12} {kl_str:>12} {ece_str:>12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vis-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "if len(ablation_results) >= 2:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    names = list(ablation_results.keys())\n",
    "    ppl_ratios = [r.get('perplexity_ratio', 0) for r in ablation_results.values()]\n",
    "    kl_divs = [r.get('kl_divergence', 0) for r in ablation_results.values()]\n",
    "    eces = [r.get('student_ece', {}).get('ece', 0) if 'student_ece' in r else 0 for r in ablation_results.values()]\n",
    "    \n",
    "    # Perplexity ratio\n",
    "    bars1 = axes[0].bar(names, ppl_ratios, color=['steelblue', 'orange', 'green', 'red'][:len(names)])\n",
    "    axes[0].set_ylabel('Perplexity Ratio')\n",
    "    axes[0].set_title('Perplexity Ratio (lower is better)')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    for bar, val in zip(bars1, ppl_ratios):\n",
    "        if val > 0:\n",
    "            axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                        f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # KL divergence\n",
    "    bars2 = axes[1].bar(names, kl_divs, color=['steelblue', 'orange', 'green', 'red'][:len(names)])\n",
    "    axes[1].set_ylabel('KL Divergence')\n",
    "    axes[1].set_title('KL Divergence (lower is better)')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    for bar, val in zip(bars2, kl_divs):\n",
    "        if val > 0:\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                        f'{val:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    # ECE\n",
    "    bars3 = axes[2].bar(names, eces, color=['steelblue', 'orange', 'green', 'red'][:len(names)])\n",
    "    axes[2].set_ylabel('Expected Calibration Error')\n",
    "    axes[2].set_title('ECE (lower is better)')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    for bar, val in zip(bars3, eces):\n",
    "        if val > 0:\n",
    "            axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                        f'{val:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Need at least 2 ablation results to create comparison plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "Based on the literature and our implementation:\n",
    "\n",
    "1. **Uncertainty-aware position weighting** should improve perplexity on difficult sequences (15-25% improvement expected)\n",
    "2. **Calibration-aware distillation** should improve ECE scores (20-30% improvement expected)\n",
    "3. **Combined enhancements** should provide benefits of both without significant interference\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- Entropy visualization shows variable uncertainty across protein sequence positions\n",
    "- Position weights correctly range from [0.5, 1.0] as designed\n",
    "- Calibration smoothing maintains valid probability distributions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Run full ablation experiments with the commands in Section 6\n",
    "2. Analyze results to validate improvements\n",
    "3. Proceed to Phase 2 (Hyperparameter Sweeps) with optimal enhancement settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
